{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Authentication failed for https://api.smith.langchain.com/runs/4cb30958-846d-4bcb-98e5-ea74ab02927c. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/4cb30958-846d-4bcb-98e5-ea74ab02927c', '{\"detail\":\"Invalid auth\"}')\n",
      "Authentication failed for https://api.smith.langchain.com/runs. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs', '{\"detail\":\"Invalid auth\"}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Victory Mansions is a building complex located in London, specifically in Airstrip One, which is the chief city of Oceania. It is described as a grimy landscape with rotting nineteenth-century houses. The houses are in a state of disrepair, with their sides supported by timber, windows patched with cardboard, and roofs made of corrugated iron. The garden walls are sagging in all directions. There are also bombed sites with rubble and plaster dust in the air, and in some areas, sordid colonies of wooden dwellings resembling chicken-houses have sprung up.\\n\\nVictory Mansions itself is overshadowed by the Ministry of Truth, which is an enormous pyramidal structure made of glittering white concrete. The building has terraces that soar 300 meters into the air. From the roof of Victory Mansions, one can see the Ministry of Truth and three other buildings of similar appearance and size. These four buildings are the homes of the four Ministries that make up the government apparatus: the Ministry of Truth, the Ministry of Peace, the Ministry of Love, and the Ministry of Plenty.\\n\\nInside Victory Mansions, there is a hallway with glass doors that Winston Smith enters. The hallway smells of boiled cabbage and old rag mats. There is a large colored poster on one end of the hallway, depicting the face of a man in his forties with a black mustache and ruggedly handsome features. The building has seven flights of stairs, as the lift is rarely working and the electricity is cut off during daylight hours. On each landing, there is a poster with the caption \"BIG BROTHER IS WATCHING YOU.\" Inside the flat, there is a telescreen, an oblong metal plaque that cannot be completely shut off, which emits a fruity voice reading out figures related to the production of pig-iron.\\n\\nIn Winston\\'s living-room, the telescreen is positioned unusually, opposite the window instead of the end wall. There is a shallow alcove in the room, possibly intended for bookshelves, where Winston sits to remain out of sight from the telescreen. The room\\'s layout and the book he recently acquired from a junk-shop inspired him to take a certain action.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these three lines swap the stdlib sqlite3 lib with the pysqlite3 package\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader # UnstructuredFileLoader는 pdf, txt, docx를 다 열 수 있음\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"../.cache/\") # embedding한 vector를 캐싱하기 위해 캐쉬 디렉토리 설정\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ") # 특정 문자열을 기준으로 끊어줌\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../../files/chapter_one.docx\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# cache embedding을 설정함으로써 embedding을 할 때, 캐시에 embedding이 이미 존재하는지 확인하고\n",
    "# 없으면 vector store를 호출할때 문서들과 OpenAIEmbeddings를 사용하게 됨\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir    \n",
    ")\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "\"\"\"\n",
    " [retriever]\n",
    "   - retriever는 여러 장소에서 document들을 가져오는 클래스의 interface임 (vector store보다 더 일반화된 형태)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "  Map Reduce chain을 구현하기 위해 아래 절차를 따름\n",
    "  1) retriever에 질문을 전달\n",
    "  2) retriever는 질문과 관련된 document의 list를 얻음\n",
    "  3) list에 있는 모든 document를 위해 prompt를 만듦\n",
    "  4) prompt'들'을 전달받은 llm은 응답'들'을 반환하고 \n",
    "  5) 모든 응답들을 묶어서 하나의 document로 합침\n",
    "  6) 최종 document를 llm에 prompt로 전달하여 결과를 획득\n",
    "\n",
    "  Q) 언제 stuff를 언제 map reduce를 사용해야할까?\n",
    "  A) retriever가 반환하는 document가 많은 경우에는 stuff를 쓸 수 없음. \n",
    "     stuff의 prompt에 모든 document를 넣을 수 없기 때문\n",
    "\"\"\"\n",
    "retriever = vectorstore.as_retriever() # retriever는 string타입의 input을 받고 관련된 문서들을 반환함\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim.\n",
    "        ------\n",
    "        {context}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\"human\",\"{question}\")\n",
    "])\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_docs(inputs):\n",
    "    # 질문과 여러개의 문서를 입력받아서 질문에 관련된 하나의 string을 반환하는 함수\n",
    "    documents = inputs['documents']\n",
    "    question = inputs['question']\n",
    "    # 여기서 document는 langchain으로부터 받는 class인데 그 중 page_content가 내용이 담긴 부분임\n",
    "    results = \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke({\n",
    "            \"context\" : doc.page_content, \"question\":question\n",
    "        }).content for doc in documents) # 각 문서에 대해 질문과 관련이 있는 부분을 추출한 모든 내용을 하나의 string으로 합침(줄바꿈을 통해 구분)\n",
    "    return results\n",
    "\n",
    "# RunnableLambda는 chain과 그 내부 어디에서든 function을 호출할 수 있도록 해줌\n",
    "map_chain = {\"documents\" : retriever, \"question\":RunnablePassthrough()} | RunnableLambda(map_docs)\n",
    "\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"\n",
    "    Given the following extracted parts of a long document and a question, create a final answer.\n",
    "    If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "    ------\n",
    "    {context}\n",
    "    \"\"\"),\n",
    "    (\"human\",\"{question}\")\n",
    "])\n",
    "\n",
    "chain = {\"context\": map_chain, \"question\":RunnablePassthrough()} | final_prompt | llm\n",
    "\n",
    "chain.invoke(\"Describe Victory Mansions\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Winston goes to work at the Ministry of Truth.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Where does Winston go to work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
