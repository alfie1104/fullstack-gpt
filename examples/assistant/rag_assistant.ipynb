{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai as client\n",
    "\n",
    "# # 처음 assistant를 생성할때는 아래 코드를 이용하면됨\n",
    "# assistant = client.beta.assistants.create(\n",
    "#     name=\"Book Assistant\",\n",
    "#     instructions=\"You help users with their question on the files they upload.\",\n",
    "#     model=\"gpt-3.5-turbo-1106\",\n",
    "#     tools=[{\"type\":\"retrieval\"}]\n",
    "# ) # 2024.03.07 현재 assistant가 beta임\n",
    "\n",
    "# 한번 생성한 assistant를 재사용할때는 id를 이용해서 사용가능\n",
    "assistant_id=\"asst_xxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread를 생성 (thread는 메시지의 그룹임). 생성한 thread는 run을 해야 llm에서 처리됨\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":\"I want you to help me with this file\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "    file=client.file_from_path(\"../../files/chapter_one.txt\"),\n",
    "    purpose=\"assistants\"\n",
    ")\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"\",\n",
    "    file_ids=[file.id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread를 실행하기 위해 run을 생성\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id\n",
    ")\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 현재(2024.3월) streaming이 지원되지 않으므로 run의 상태가 어떤지 알기 위해서 계속 물어봐야함\n",
    "def get_run(run_id, thread_id):\n",
    "    return client.beta.threads.runs.retrieve(\n",
    "        run_id=run_id,\n",
    "        thread_id=thread_id,\n",
    "    )\n",
    "\n",
    "def get_messages(thread_id):\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread_id\n",
    "    )\n",
    "    messages = list(messages)\n",
    "    messages.reverse()\n",
    "    for message in messages:\n",
    "        if len(message.content) >= 1:\n",
    "            print(f\"{message.role}: {message.content[0].text.value}\")\n",
    "            for annotation in message.content[0].text.annotations:\n",
    "                print(f\"Source: {annotation.file_citation}\")\n",
    "        else:\n",
    "            print(f\"{message.role}: No content\")\n",
    "\n",
    "def send_message(thread_id, content):\n",
    "    return client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=content\n",
    "    )\n",
    "\n",
    "def cancel_run(run_id, thread_id):\n",
    "    return client.beta.threads.runs.cancel(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run_id\n",
    "    )\n",
    "\n",
    "def delete_thread(thread_id):\n",
    "    return client.beta.threads.delete(\n",
    "        thread_id=thread_id\n",
    "    )\n",
    "\n",
    "def get_tool_outputs(run_id, thread_id):\n",
    "    run = get_run(run_id, thread_id)\n",
    "    outputs = []\n",
    "    for action in run.required_action.submit_tool_outputs.tool_calls:\n",
    "        action_id = action.id\n",
    "        function = action.function\n",
    "        print(f\"Calling function: {function.name} with arg {function.arguments}\")\n",
    "        # ai가 실행하라고 한 함수를 실행. 함수는 미리 functions_map에 담아놨음\n",
    "        outputs.append({\n",
    "            \"output\": functions_map[function.name](json.loads(function.arguments)),\n",
    "            \"tool_call_id\":action_id\n",
    "        })\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def submit_tool_outputs(run_id, thread_id):\n",
    "    outputs = get_tool_outputs(run_id, thread_id)\n",
    "    return client.beta.threads.runs.submit_tool_outputs(\n",
    "        run_id = run_id,\n",
    "        thread_id=thread_id,\n",
    "        tool_outputs=outputs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_run(run.id, thread.id).status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_messages(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_message(thread.id, \"Where does he work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
