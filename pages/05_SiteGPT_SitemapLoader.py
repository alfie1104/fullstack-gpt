from langchain.document_loaders import SitemapLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import streamlit as st

import asyncio
asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy()) # windowì—ì„œ NotImplementedErrorê°€ ë°œìƒí•˜ê¸° ë•Œë¬¸ì— ì¶”ê°€í•˜ì˜€ìŒ

#  [SitemapLoader]
#  - sitemap.xml íŒŒì¼ì„ ê°€ì§€ê³  ìˆëŠ” ì‚¬ì´íŠ¸ì— ëŒ€í•´ì„œëŠ” SitemapLoaderë¥¼ ì´ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤.
#  - AsyncChromiumLoaderì˜ ê²½ìš° ì—¬ëŸ¬ê°œì˜ ì‚¬ì´íŠ¸ì— ëŒ€í•´ì„œ html ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ë ¤ê³  í•  ê²½ìš°, chromium browserê°€ ì—¬ëŸ¬ê°œ ì—´ë ¤ì•¼ í•˜ë¯€ë¡œ ì†ë„ê°€ ëŠë ¤ì§ˆ ìˆ˜ ìˆì§€ë§Œ
#  - SitemapLoaderëŠ” chromiumì„ ì‚¬ìš©í•˜ì§€ ì•Šì•„ì„œ ìœ„ì™€ ê°™ì€ ë¬¸ì œê°€ ì—†ìŒ
#  - ë˜í•œ AsyncChromiumLoaderì™€ ë‹¬ë¦¬ SitemapLoaderëŠ” html ë°ì´í„°ë¥¼ ì •ë¦¬í•´ì„œ textë§Œ ë½‘ì•„ì˜´(ê·¸ëŸ°ë° ë©”ë‰´, ë„¤ë¹„ê²Œì´ì…˜ ë“±ì˜ í…ìŠ¤íŠ¸ë“¤ë„ ë½‘ì•„ì˜¤ê¸° ë•Œë¬¸ì— í•„ìš”ì—†ëŠ” ë‚´ìš©ì´ ë§ìŒ)
#  - ë„ˆë¬´ ë¹ ë¥´ê²Œ scrappingì„ í•˜ë©´ ì°¨ë‹¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ default ì„¤ì •ìœ¼ë¡œ SitemapLoaderëŠ” 1ì´ˆì— í•œë²ˆì”© ìš”ì²­ì„ ë³´ëƒ„
#  - ì†ë„ë¥´ ë” ì¤„ì´ë ¤ë©´ SitemapLoader(url).requests_per_second í•¨ìˆ˜ë¥¼ í†µí•´ ì¡°ì ˆí•  ìˆ˜ ìˆìŒ
#  - SitemapLoaderëŠ” pageë¡œë¶€í„° ëª¨ë“  textë¥¼ ì¶”ì¶œí•˜ê³  htmlì„ ì œê±°í•˜ê¸° ìœ„í•´ ë‚´ë¶€ì ìœ¼ë¡œ beautiful soup(soup is just bunch of html) ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŒ.
#  - parsing_function ì†ì„±ì„ ì„¤ì •í•˜ë©´ beautiful soupì˜ ë™ì‘ì„ ì¡°ì •í•  ìˆ˜ ìˆìŒ

llm = ChatOpenAI(
    temperature=0.1
)

answers_prompt = ChatPromptTemplate.from_template("""
    Using ONLY the following context answer the user's question. If you can't just say you don't know, don't make anything up.
                                                  
    Then, give a score to the answer between 0 and 5.
    If the answer answers the user question the score should be high, else it should be low.
    Make sure to always include the answer's score even if it's 0.
    Context: {context}
                                                  
    Examples:
                                                  
    Question: How far away is the moon?
    Answer: The moon is 384,400 km away.
    Score: 5
                                                  
    Question: How far away is the sun?
    Answer: I don't know
    Score: 0
                                                  
    Your turn!
    Question: {question}
""")

def get_answers(inputs):
    docs = inputs["docs"]
    question = inputs["question"]
    answers_chain = answers_prompt | llm

    # answers = []
    # for doc in docs:
    #     result = answers_chain.invoke({
    #         "question":question,
    #         "context":doc.page_content
    #     })
    #     answers.append(result.content)
    return [
        {
            "answer" : answers_chain.invoke({
                    "question":question,"context":doc.page_content
                }).content,
            "source": doc.metadata["source"],
            "date" : doc.metadata["lastmod"],
        } for doc in docs
    ]

def parse_page(soup):
    # beautiful soupê°€ ìƒì„±í•˜ëŠ” soup objectë¥¼ ì´ìš©í•´ì„œ í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ

    # ë‹¤ìŒê³¼ ê°™ì´ headerì™€ footer íƒœê·¸ë¥¼ ì°¾ì•„ì„œ soupì—ì„œ ì œê±°í•  ìˆ˜ ìˆìŒ
    header = soup.find("header")
    footer = soup.find("footer")
    if header:
        header.decompose()
    if footer:
        footer.decompose()
    # return soup.get_text() # headerì™€ footerë¥¼ ì œê±°í•œ ë‚˜ë¨¸ì§€ textë¥¼ ë°˜í™˜
    
    # soupì—ì„œ ë°˜í™˜í•œ textì—ì„œ í•„ìš”ì—†ëŠ” ë¬¸ìë“¤ì„ ì œê±°
    return (
        str(soup.get_text())
        .replace("\n"," ")
        .replace("\xa0"," ") # \xa0 : non-breaking-space
        .replace("CloseSearch Submit Blog", "")
    )


@st.cache_data(show_spinner="Loading website...")
def load_website(url):    
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000,
        chunk_overlap=200
    )

    loader = SitemapLoader(
        url 
        # , filter_urls=["https://openai.com/blog/data-partnerships"] # filter_urlsë¥¼ ì´ìš©í•˜ë©´ sitemap.xmlì— ìˆëŠ” ì‚¬ì´íŠ¸ ë“¤ ì¤‘ íŠ¹ì • ì‚¬ì´íŠ¸ì˜ ë°ì´í„°ë§Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
        # , filter_urls=[r"^(?!.*\/blog\/).*"] # ì •ê·œí‘œí˜„ì‹ì„ ì´ìš©í•´ì„œ /blog/ë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ” ì‚¬ì´íŠ¸ë§Œ ê°€ì ¸ì˜´
        # , filter_urls=[r"^(.*\/blog\/).*"] # ì •ê·œí‘œí˜„ì‹ì„ ì´ìš©í•´ì„œ /blog/ë¥¼ í¬í•¨í•˜ëŠ” ì‚¬ì´íŠ¸ë§Œ ê°€ì ¸ì˜´
        , parsing_function=parse_page # SitemapLoaderê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” beautiful soupì˜ ë™ì‘ì„ ì¡°ì •í•˜ê¸° ìœ„í•´ì„œ parsing_function ì†ì„±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
    )
    loader.requests_per_second = 5
    # docs = loader.load()
    docs = loader.load_and_split(text_splitter=splitter) # ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì‘ê²Œ ì˜ë¼ì„œ ë°˜í™˜í•˜ë„ë¡ í•˜ê¸° ìœ„í•´ text_splittertì‚¬ìš©
    # return docs

    vector_store = FAISS.from_documents(docs, OpenAIEmbeddings()) # documentë¥¼ ê²€ìƒ‰ì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì„ë² ë”© í›„ vector storeì— ì €ì¥
    return vector_store.as_retriever() # vector storeë¥¼ chainì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ retriever(ì§ˆë¬¸ ì¿¼ë¦¬ì— ì í•©í•œ documentë¥¼ ë°˜í™˜í•´ì¤Œ)ë¡œ ë°˜í™˜(retrieverëŠ” invoke ë©”ì†Œë“œë¥¼ ê°€ì§€ê³  ìˆì–´ì„œ chainì—ì„œ ì‹¤í–‰ê°€ëŠ¥í•¨)
    

st.set_page_config(
    page_title="SiteGPT",
    page_icon="ğŸ’»"
)

st.title("SiteGPT")


st.markdown("""
Ask questions about the content of a website.

Start by writing the URL of the website on the sidebar.
""")

with st.sidebar:
    url = st.text_input(
        "Write down a URL", 
        placeholder="https://example.com"
    )

if url:
    if ".xml" not in url:
        with st.sidebar:
            st.error("Please wright down a Sitemap URL.")
    else:
        # docs = load_website(url)
        retriever = load_website(url) # ê¸°ì¡´ì—ëŠ” load_websiteê°€ documentë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í–ˆì§€ë§Œ ì´ì œ retrieverë¡œ ë°˜í™˜
        # Map Re Rank Chain
        # retrieverë¡œ ë¶€í„° ë°›ì€ documentë¥¼ ì‚´í´ë³´ê³  ê·¸ documentë“¤ì„ llmì—ê²Œ ì „ë‹¬í•˜ë©´ì„œ, í•´ë‹¹ documentë“¤ë¡œë§Œ ì‚¬ìš©ìì˜ questionì— ë‹µë³€í•´ë‹¬ë¼ê³  ìš”ì²­í•¨
        # ê·¸ë¦¬ê³  ë‚˜ì„œ ê° documentë¥¼ ì´ìš©í•˜ì—¬ ë‹µë³€ë“¤ì´ ìƒì„±ë˜ë©´, llmì—ê²Œ ë‹µë³€ì˜ ìœ ìš©í•œ ì •ë„ë¥¼ í‰ê°€í•´ë‹¬ë¼ê³  ìš”ì²­í•¨
        # ëª¨ë“  ë‹µë³€ê³¼ ì ìˆ˜ëŠ” ë˜ ë‹¤ë¥¸ promptì—ê²Œ ì…ë ¥ë˜ê³ , ê·¸ promptëŠ” ë‹¤ì‹œ llmì— ì „ë‹¬ë˜ì–´
        # 'ì£¼ì–´ì§„ ë‹µë³€ë“¤ ì¤‘ ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°–ê³  ê°€ì¥ ìµœê·¼ì— ì‘ì„±ëœ ê²ƒì„ ì„ íƒí•´ì¤˜'ë¼ê³  ìš”ì²­
        # ë”°ë¼ì„œ 2ê°œì˜ chainì´ í•„ìš”í•¨. 1) ë‹µë³€ ìƒì„± ë° ì±„ì  ë‹´ë‹¹ / 2) ì ìˆ˜ê°€ ì œì¼ ë†’ê³  ê°€ì¥ ìµœì‹ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” ë‹µë³€ì„ ê³ ë¥´ëŠ” chain

        # questionì´ retrieverë¡œ ì „ë‹¬ë˜ì–´ì„œ retrieverëŠ” docsë¥¼ ë°˜í™˜í•˜ê³ ,
        # ë™ì¼í•œ questionì´ ë‹¤ì‹œ question íŒŒë¼ë¯¸í„°ì— í• ë‹¹ë¨
        # retrieverë¡œë¶€í„° ë°˜í™˜ë°›ì€ docsì™€ question íŒŒë¼ë¯¸í„°ë¥¼ get_answer í•¨ìˆ˜ì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬
        # get_answersëŠ” ê° docë§ˆë‹¤ ë‹µë³€ ë° ì ìˆ˜ë¥¼ ë°˜í™˜í•¨
        chain = {
            "docs":retriever, 
            "question":RunnablePassthrough()
        } | RunnableLambda(get_answers) # docsì™€ questionì´ get_answersí•¨ìˆ˜ì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ë¨
        # | RunnableLambda(choose_answer)

        chain.invoke("What is the pricing of GPT-4 Turbo with vision.")